{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"newvgg.ipynb","provenance":[{"file_id":"1Y334WcOPcPLL4kSqHZ8WSkwfMbCPLdow","timestamp":1581607413905}],"collapsed_sections":[],"mount_file_id":"1S1_1TxMbrLqxWoKDtwRWTfv2tRK_RU5B","authorship_tag":"ABX9TyOkDrJzT+bO5+KOqHy3e1Ey"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tGyHXGBO9ad6","colab_type":"text"},"source":["## Importing the Keras libraries and packages."]},{"cell_type":"code","metadata":{"id":"XGwMbul0hnm7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"f47fcf3c-628b-4692-b889-e2d82e60ee4e","executionInfo":{"status":"ok","timestamp":1590996318910,"user_tz":-330,"elapsed":2821,"user":{"displayName":"finalyear project","photoUrl":"","userId":"03643863008562068783"}}},"source":["import tensorflow \n","import keras\n","from keras.models import Sequential,Model\n","from keras.layers import Conv2D,Dense,Dropout,MaxPooling2D,Flatten,Input,ZeroPadding2D,LeakyReLU\n","\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import SGD\n","\n","import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from keras.callbacks import ModelCheckpoint\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"HMVtlFcE9mh8","colab_type":"text"},"source":["## Checking the correct version."]},{"cell_type":"code","metadata":{"id":"54Xd7c0Ry-dB","colab_type":"code","colab":{}},"source":["# !pip uninstall  tensorflow\n","# !pip uninstall  keras\n","\n","# !pip install  tensorflow==1.15\n","# !pip install  keras==2.1.6\n","#printing the versions\n","import keras as k\n","import tensorflow as tf\n","print(tf.__version__)\n","print(k.__version__)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LELzkaOI92uF","colab_type":"text"},"source":["## Download the keras_vggface weights.\n"]},{"cell_type":"code","metadata":{"id":"EpZQ8kUiYMlT","colab_type":"code","colab":{}},"source":["!pip install keras_vggface"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R4l4QcM--OeO","colab_type":"text"},"source":["## Building the model."]},{"cell_type":"code","metadata":{"id":"F7N7rnkshzJW","colab_type":"code","colab":{}},"source":["#importing the model\n","from keras_vggface.vggface import VGGFace\n","from keras.utils.vis_utils import plot_model\n"," \n","#Specifie the width and height\n","img_width=240\n","img_height=300\n","\n","\n","#Initializing the model \n","custom_vgg_model = VGGFace(weights=\"vggface\", include_top=False,\n","\tinput_tensor=Input(shape=(img_width, img_height, 3)))\n","# custom_vgg_model.summary()\n","\n","\n","#Counting the layers\n","layer_count = 0\n","for layer in custom_vgg_model.layers:\n","\tlayer_count = layer_count+1\n","\n","#Freezing the layers(except last 4 layers)\n","for l in range(layer_count-4):#-3 \n","\tcustom_vgg_model.layers[l].trainable=False\n","\t# print(custom_vgg_model.layers[l])\n","\t# print(l)\n","\n","#Now,Except the last 4 layers all layers are freezed\t\n","# custom_vgg_model.summary()\n","\n","#Covert the layers to Sequential for training\n","model = Sequential()\n","for layer in custom_vgg_model.layers:\n","\t# print(layer)\n","\tmodel.add(layer)\n","# model.summary()\n","\n","#Now flatten the layers\n","model.add(Flatten())\n","model.add(Dropout(0.3))\n","#Add Dense layers\n","model.add(Dense(units = 2056, activation = 'relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(units = 1056, activation = 'relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(units = 256, activation = 'relu'))\n","#The last layer must contain 5 units(because we have 5 class to recognize)\n","model.add(Dense(units = 5, activation = 'softmax'))\n","# model.summary()\n","#Save the model architecture\n","plot_model(model, to_file='/content/drive/My Drive/Colab Notebooks/model_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9uIc9P6x-S5R","colab_type":"text"},"source":["## Compiling the model."]},{"cell_type":"code","metadata":{"id":"qDsSid1gGvP6","colab_type":"code","colab":{}},"source":["#Import the optimizer\n","from keras.optimizers import Adam\n","#the optimizer is initialized with learning rate\n","opt = Adam(lr=1e-4)\n","#Compile the model with loss function categorical_crossentropy and optimizer Adam and output the accuracy \n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n","\tmetrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"egkawYVG-XX5","colab_type":"text"},"source":["## Training the model."]},{"cell_type":"code","metadata":{"id":"h0m40iZAj9IM","colab_type":"code","colab":{}},"source":["#Initializing the variabels to respective directories(On Right side find the directory and right click copy path and past it)\n","train_data_dir = \"/content/drive/My Drive/Colab Notebooks/dataset1/train\"\n","val_data_dir   = \"/content/drive/My Drive/Colab Notebooks/dataset1/val\"\n","test_data_dir   = \"/content/drive/My Drive/Colab Notebooks/dataset1/test\"\n","\n","\n","\n","\n","batch_size=32\n","nb_epochs = 5\n","chfile = \"/content/drive/My Drive/Colab Notebooks/faceacc3.hdf5\"\n","#Checkpoints to get good results\n","#These checkpoints are monitored val_loss(it needs to be minimized),val_acc(it needs to be maximized),loss(it needs to be minimized),acc(it needs to be maximized)\n","checkpoints = [ModelCheckpoint(chfile,monitor = \"val_loss\",verbose=1,save_best_only=True,mode=\"min\",period=1),\n","              ModelCheckpoint(chfile,monitor = \"val_acc\",verbose=1,save_best_only=True,mode=\"max\",period=1),\n","              ModelCheckpoint(chfile,monitor = \"loss\",verbose=1,save_best_only=True,mode=\"min\",period=1),\n","              ModelCheckpoint(chfile,monitor = \"acc\",verbose=1,save_best_only=True,mode=\"max\",period=1)]\n","\n","\n","\n","#Preaper the dataset for training\n","train_datagen = ImageDataGenerator(rescale=1./255, \n","                                   brightness_range=[0.3,2.0]\n","                                  )\n","\n","train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(img_width, img_height),\n","        classes=['aka','pra','rah','shr','unk'],\n","        batch_size=batch_size,\n","        class_mode='categorical')\n","\n","\n","\n","#Preaper the dataset for validation\n","validation_datagen = ImageDataGenerator(rescale=1./255, \n","                                   brightness_range=[0.3,1.3]\n","                                  )\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","        val_data_dir,\n","        target_size=(img_width, img_height),\n","        classes=['aka','pra','rah','shr','unk'],\n","        batch_size=batch_size,\n","         class_mode='categorical'\n","         )\n","\n","# steps_per_epoch should be (number of training images total / batch_size) \n","# validation_steps should be (number of validation images total / batch_size) \n","\n","history = model.fit_generator(\n","              train_generator,\n","              validation_data = validation_generator, \n","              steps_per_epoch = train_generator.samples // batch_size,\n","              validation_steps = validation_generator.samples // batch_size,\n","              epochs = nb_epochs,\n","              callbacks=checkpoints)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rS3VLdnd-dhq","colab_type":"text"},"source":["## Ploting the model."]},{"cell_type":"code","metadata":{"id":"rDXsBoB9kVcn","colab_type":"code","colab":{}},"source":["import keras\n","from matplotlib import pyplot as plt\n","\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['acc','val_acc','loss','val_loss'], loc='upper left')#,'tloss','vloss',\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-NgBCDlq-iQJ","colab_type":"text"},"source":["## Getting the test score(optinal)."]},{"cell_type":"code","metadata":{"id":"jzjZjYrJU35G","colab_type":"code","outputId":"f9de951a-145b-4f6d-efb5-ca1db78dcca9","executionInfo":{"status":"ok","timestamp":1583843192694,"user_tz":-330,"elapsed":18872,"user":{"displayName":"finalyear project","photoUrl":"","userId":"03643863008562068783"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["#Prepare the dataset for testing\n","test_datagen = ImageDataGenerator(rescale=1./255,\n","                                   brightness_range=[0.4,2.0])\n","test_generator = test_datagen.flow_from_directory(\n","        val_data_dir,\n","        target_size=(img_width, img_height),\n","        classes=['aka','pra','rah','shr','unk'],\n","        batch_size=batch_size)\n","\n","#Get the score\n","score = model.evaluate_generator(validation_generator, 100)\n","print(\"Accuracy = \",score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 50 images belonging to 5 classes.\n","Accuracy =  0.9737446669637081\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mKdNsyBO-oS5","colab_type":"text"},"source":["## Saving the model."]},{"cell_type":"code","metadata":{"id":"aJMF1ncJu5Q7","colab_type":"code","colab":{}},"source":["#Save the model\n","model.save('/content/drive/My Drive/Colab Notebooks/modelname.hdf5')  # creates a HDF5 file 'my_model.h5'\n","del model  # deletes the existing model\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TNCVwIwi_ff4","colab_type":"text"},"source":["## Testing the model."]},{"cell_type":"code","metadata":{"id":"EYX1JFrJ_QD9","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","from keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","#Load the model\n","model = load_model('/content/drive/My Drive/Colab Notebooks/faceacc3.hdf5')\n","# model.summary()\n","\n","path =\"path to image\"\n","# /content/drive/My Drive/Colab Notebooks/dataset/test/a/ (1).jpg\n","\n","test_image = image.load_img(path, target_size = (240,300))\n","test_image = image.img_to_array(test_image)\n","plt.imshow(test_image/255.)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = model.predict(test_image)\n","\n","result1 = model.predict_proba(test_image/255)\n","predicted_classes = np.argmax(result1,axis=1)\n","print(result)\n","\n","\n","print('confidence : {:.3f}'.format(result1[0][predicted_classes[0]]))\n","\n","if result[0][0]:\n","    print(\"aka\")\n","elif result[0][1]:\n","    print(\"pra\")\n","elif result[0][2]:\n","    print(\"rah\")\n","elif result[0][3]:\n","    print(\"shy\")\n","elif result[0][4]:\n","    print(\"unknown\")\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-cFkAqzU-z6v","colab_type":"text"},"source":["## Testing the entier test folder model\n","### In test folder the images should be numbered from 1 to 10(you can add more) for all students images."]},{"cell_type":"code","metadata":{"id":"F-mMKwZjdAxM","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","from keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","#Load the model\n","model = load_model('/content/drive/My Drive/Colab Notebooks/faceacc3.hdf5')\n","# model.summary()\n","\n","s=[\"aka\",\"pra\",\"rah\",\"shr\",\"unk\"]\n","# print(train_generator.class_indices)\n","for i in range(5):\n","  for j in range(1,11):\n","    path =\"/content/drive/My Drive/Colab Notebooks/dataset1/test/\"+s[i]+\"/ (\"+str(j)+\").jpg\"\n","    # /content/drive/My Drive/Colab Notebooks/dataset/test/a/ (1).jpg\n","\n","    test_image = image.load_img(path, target_size = (240,300))\n","    test_image = image.img_to_array(test_image)\n","    plt.imshow(test_image/255.)\n","    test_image = np.expand_dims(test_image, axis = 0)\n","    result = model.predict(test_image)\n","\n","    result1 = model.predict_proba(test_image/255)\n","    predicted_classes = np.argmax(result1,axis=1)\n","    print(result)\n","\n","\n","    print('confidence : {:.3f}'.format(result1[0][predicted_classes[0]]))\n","\n","    if result[0][0]:\n","        print(\"aka\")\n","    elif result[0][1]:\n","        print(\"pra\")\n","    elif result[0][2]:\n","        print(\"rah\")\n","    elif result[0][3]:\n","        print(\"shy\")\n","    elif result[0][4]:\n","        print(\"unknown\")\n"],"execution_count":0,"outputs":[]}]}
