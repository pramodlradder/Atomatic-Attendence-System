{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the tensorflow,Keras libraries \n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,Input    \n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "# Importing opencv libraries \n",
    "import imutils\n",
    "import cv2\n",
    "from imutils.video import VideoStream\n",
    "\n",
    "# Importing the basic libraries\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our serialized face detector \n",
    "print(\"[INFO] loading face detector...\")\n",
    "protoPath = \"face_detection_model/deploy.prototxt\"\n",
    "modelPath = \"face_detection_model/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "detector = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "print(\"Done\")\n",
    "#Create directory to save original image along with recognized faces.\n",
    "if not os.path.exists(\"outputs\"):\n",
    "    os.mkdir(\"outputs\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "#for time calculation %time\n",
    "#load model\n",
    "from keras.models import load_model\n",
    "model = load_model('models/faceacc3.hdf5')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves Images to output directory.It will show bounding box in output screen.\n",
    "Press 'c' to perform the recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize the video stream, then allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "#time delay for loading the camera\n",
    "time.sleep(2.0)\n",
    "#for counting the unknown people\n",
    "j=0\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream\n",
    "    frame = vs.read()\n",
    "    # resize the frame to have a width of 800 pixels (while\n",
    "    # maintaining the aspect ratio), and then grab the image\n",
    "    # dimensions\n",
    "    frame = imutils.resize(frame, width=800)\n",
    "    (h, w) = frame.shape[:2]\n",
    "    #A variable to hold the press event of key 'c' (initialy False)\n",
    "    save = False\n",
    "    #Capturing the key Strokes\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    #If c is pressed save the faces    \n",
    "    if key == ord(\"c\"):\n",
    "        #create a folder name with time stamp\n",
    "        original = str(time.strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "        #creating the directory\n",
    "        os.mkdir(\"outputs/\"+original)\n",
    "        #Save the original image        \n",
    "        cv2.imwrite(\"outputs/\"+str(original)+\"/\"+\"original.jpg\",frame) \n",
    "        #Variable that helps in saving the face images\n",
    "        save = True\n",
    "        \n",
    "        print(\"done\")\n",
    "\n",
    "\n",
    "    # construct a blob from the image\n",
    "    imageBlob = cv2.dnn.blobFromImage(\n",
    "        cv2.resize(frame, (300, 300)), 1.0, (300, 300),\n",
    "        (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "    # apply OpenCV's deep learning-based face detector to localize\n",
    "    # faces in the input image\n",
    "    detector.setInput(imageBlob)\n",
    "    detections = detector.forward()\n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with\n",
    "        # the prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        # filter out weak detections\n",
    "        if confidence > 0.5:\n",
    "            # compute the (x, y)-coordinates of the bounding box for\n",
    "            # the face\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            # extract the face ROI\n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            (fH, fW) = face.shape[:2]\n",
    "            # ensure the face width and height are sufficiently large\n",
    "            if fW < 20 or fH < 20:\n",
    "                continue\n",
    "\n",
    "            #face = cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n",
    "            #Resize the image as per the model dimensions\n",
    "            test_image = cv2.resize(face,(300,240))\n",
    "            #Convert image to array\n",
    "            test_image = image.img_to_array(test_image)\n",
    "            #Convert image to single dimensional array\n",
    "            test_image = np.expand_dims(test_image, axis = 0)\n",
    "            #Predict the image\n",
    "            result = model.predict(test_image)\n",
    "            #probability estimation\n",
    "            proba = model.predict_proba(test_image/255)\n",
    "            #Class estimation\n",
    "            predicted_classes = np.argmax(proba,axis=1)\n",
    "#             print(result)\n",
    "            if result[0][0]:\n",
    "                name = \"Aka\"\n",
    "            elif result[0][1]:\n",
    "                name = \"Pramod\"\n",
    "            elif result[0][2]:\n",
    "                name = \"Rahul\"\n",
    "            elif result[0][3]:\n",
    "                name = \"Shreyas\"\n",
    "            elif result[0][4]:\n",
    "                name = \"Unknown\"\n",
    "            if name == \"Unknown\":\n",
    "                name = \"Unknown\"+str(i)+\" \"\n",
    "\n",
    "            #Save the faces only key 'c' is pressed\n",
    "            if save:\n",
    "                cv2.imwrite(\"outputs/\"+str(original)+\"/\"+str(name)+\".jpg\",face) \n",
    "\n",
    "            # draw the bounding box of the face along with the\n",
    "            # associated probability\n",
    "            text = \"{}: {:.2f}%\".format(name, proba[0][predicted_classes[0]] * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY),(0, 0, 255), 2)\n",
    "            cv2.putText(frame, text, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 2)\n",
    "        \n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saves only Images to output directory.It will not show bounding box in output screen.\n",
    "Press 'c' to perform the recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the video stream, then allow the camera sensor to warm up\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "#time delay for loading the camera\n",
    "time.sleep(2.0)\n",
    "#for counting the unknown people\n",
    "j=0\n",
    "# loop over frames from the video file stream\n",
    "while True:\n",
    "    # grab the frame from the  video stream\n",
    "    frame = vs.read()\n",
    "    # resize the frame to have a width of 800 pixels (while\n",
    "    # maintaining the aspect ratio), and then grab the image\n",
    "    # dimensions\n",
    "    frame = imutils.resize(frame, width=800)\n",
    "    (h, w) = frame.shape[:2]    \n",
    "    #Capturing the key Strokes\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    #If c is pressed perform detection of faces\n",
    "    if key == ord(\"c\"):\n",
    "        #create a folder name with time stamp\n",
    "        original = str(time.strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "        #creating the directory\n",
    "        os.mkdir(\"outputs/\"+original)\n",
    "        #Save the original image\n",
    "        cv2.imwrite(\"outputs/\"+str(original)+\"/\"+\"original.jpg\",frame) \n",
    "        \n",
    "        print(\"done\")\n",
    "\n",
    "        # construct a blob from the image\n",
    "        imageBlob = cv2.dnn.blobFromImage(\n",
    "            cv2.resize(frame, (300, 300)), 1.0, (300, 300),\n",
    "            (104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "        # apply OpenCV's deep learning-based face detector to localize\n",
    "        # faces in the input image\n",
    "        detector.setInput(imageBlob)\n",
    "        detections = detector.forward()\n",
    "        # loop over the detections\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated with\n",
    "            # the prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "\n",
    "            # filter out weak detections\n",
    "            if confidence > 0.5:\n",
    "                # compute the (x, y)-coordinates of the bounding box for\n",
    "                # the face\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                # extract the face ROI\n",
    "                face = frame[startY:endY, startX:endX]\n",
    "                (fH, fW) = face.shape[:2]\n",
    "                # ensure the face width and height are sufficiently large\n",
    "                if fW < 20 or fH < 20:\n",
    "                    continue\n",
    " \n",
    "                #face = cv2.cvtColor(face,cv2.COLOR_BGR2RGB)\n",
    "                #Resize the image as per the model dimensions\n",
    "                test_image = cv2.resize(face,(300,240))\n",
    "                #Convert image to array\n",
    "                test_image = image.img_to_array(test_image)\n",
    "                #Convert image to single dimensional array\n",
    "                test_image = np.expand_dims(test_image, axis = 0)\n",
    "                #Predict the image\n",
    "                result = model.predict(test_image)\n",
    "                #probability estimation\n",
    "                proba = model.predict_proba(test_image/255)\n",
    "                #Class estimation\n",
    "                predicted_classes = np.argmax(proba,axis=1)\n",
    "                #print(result)\n",
    "                if result[0][0]:\n",
    "                    name = \"Akashya\"\n",
    "                elif result[0][1]:\n",
    "                    name = \"Pramod\"\n",
    "                elif result[0][2]:\n",
    "                    name = \"Rahul\"\n",
    "                elif result[0][3]:\n",
    "                    name = \"Shreyas\"\n",
    "                elif result[0][4]:\n",
    "                    name = \"Unknown\"\n",
    "                if name == \"Unknown\":\n",
    "                    name = \"Unknown\"+str(i)+\" \"\n",
    "                \n",
    "\n",
    "                #Save the face images \n",
    "                cv2.imwrite(\"outputs/\"+str(original)+\"/\"+str(name)+\".jpg\",face) \n",
    "\n",
    "        \n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    #cv2.imshow(\"face\", face)\n",
    "\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "#Relase all resourses\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageTk, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import cv2\n",
    "import tkinter\n",
    "root = Tk()\n",
    "# Create a frame\n",
    "app = Frame(root, bg=\"white\")\n",
    "app.grid()\n",
    "# Create a label in the frame\n",
    "lmain = Label(app)\n",
    "lmain.grid(row=0,column = 0)\n",
    "\n",
    "# Capture from camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# function for video streaming\n",
    "def video_stream():\n",
    "    _, frame = cap.read()\n",
    "    cv2image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGBA)\n",
    "    img = Image.fromarray(cv2image)\n",
    "    imgtk = ImageTk.PhotoImage(image=img)\n",
    "    lmain.imgtk = imgtk\n",
    "    lmain.configure(image=imgtk)\n",
    "    lmain.after(1, video_stream) \n",
    "\n",
    "    \n",
    "def helloCallBack():\n",
    "    tkMessageBox.showinfo( \"Hello Python\", \"Hello World\")\n",
    "    \n",
    "B = tkinter.Button(root, text =\"Capture\", command = video_stream)\n",
    "B.grid(row=1)    \n",
    "\n",
    "\n",
    "scrollbar = Scrollbar(root,orient=VERTICAL)\n",
    "scrollbar.pack(side = RIGHT, anchor = NW,fill=\"x\")\n",
    "\n",
    "\n",
    "# B = tkinter.Button(root, text =\"imge\", command = video_stream)\n",
    "# B.grid(row=0,column = 1)    \n",
    "\n",
    "# video_stream()\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "import tkinter as tki\n",
    "import threading\n",
    "import datetime\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class PhotoBoothApp:\n",
    "    def __init__(self, vs, outputPath=r\"C:\\Users\\dell5567\\Desktop\\projectF\\outputs\"):\n",
    "        # store the video stream object and output path, then initialize\n",
    "        # the most recently read frame, thread for reading frames, and\n",
    "        # the thread stop event\n",
    "        self.vs = vs\n",
    "        self.outputPath = outputPath\n",
    "        self.frame = None\n",
    "        self.thread = None\n",
    "        self.stopEvent = None\n",
    "        # initialize the root window and image panel\n",
    "        self.root = tki.Tk()\n",
    "        self.panel = None\n",
    "\n",
    "        # create a button, that when pressed, will take the current\n",
    "        # frame and save it to file\n",
    "        btn = tki.Button(self.root, text=\"Snapshot!\",\n",
    "            command=self.takeSnapshot)\n",
    "        btn.pack(side=\"bottom\", fill=\"both\", expand=\"yes\", padx=10,\n",
    "            pady=10)\n",
    "        \n",
    "        \n",
    "#         !!!!!!!!!!\n",
    "        scrollbar = tki.Scrollbar(self.root)\n",
    "        scrollbar.pack(side=\"right\", fill=\"y\") \n",
    "\n",
    "         \n",
    "        \n",
    "#         !!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # start a thread that constantly pools the video sensor for\n",
    "        # the most recently read frame\n",
    "        self.stopEvent = threading.Event()\n",
    "        self.thread = threading.Thread(target=self.videoLoop, args=())\n",
    "        self.thread.start()\n",
    "        # set a callback to handle when the window is closed\n",
    "#         self.root.wm_title(\"PyImageSearch PhotoBooth\")\n",
    "#         self.root.wm_protocol(\"WM_DELETE_WINDOW\", self.onClose)\n",
    "\n",
    "    def videoLoop(self):\n",
    "        # DISCLAIMER:\n",
    "        # I'm not a GUI developer, nor do I even pretend to be. This\n",
    "        # try/except statement is a pretty ugly hack to get around\n",
    "        # a RunTime error that Tkinter throws due to threading\n",
    "        try:\n",
    "            # keep looping over frames until we are instructed to stop\n",
    "            while not self.stopEvent.is_set():\n",
    "                # grab the frame from the video stream and resize it to\n",
    "                # have a maximum width of 300 pixels\n",
    "                self.frame = self.vs.read()\n",
    "                self.frame = imutils.resize(self.frame, width=400)\n",
    "\n",
    "                # OpenCV represents images in BGR order; however PIL\n",
    "                # represents images in RGB order, so we need to swap\n",
    "                # the channels, then convert to PIL and ImageTk format\n",
    "                image = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)\n",
    "                image = Image.fromarray(image)\n",
    "                image = ImageTk.PhotoImage(image)\n",
    "\n",
    "                # if the panel is not None, we need to initialize it\n",
    "                if self.panel is None:\n",
    "                    self.panel = tki.Label(image=image)\n",
    "                    self.panel.image = image\n",
    "                    self.panel.pack(side=\"left\", padx=10, pady=10)\n",
    "\n",
    "                # otherwise, simply update the panel\n",
    "                else:\n",
    "                    self.panel.configure(image=image)\n",
    "                    self.panel.image = image\n",
    "        except RuntimeError:            \n",
    "            print(\"[INFO] caught a RuntimeError\")\n",
    "\n",
    "    def takeSnapshot(self):\n",
    "        # grab the current timestamp and use it to construct the\n",
    "        # output path\n",
    "        ts = datetime.datetime.now()\n",
    "        filename = \"{}.jpg\".format(ts.strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "        p = os.path.sep.join((self.outputPath, filename))\n",
    "        # save the file\n",
    "        cv2.imwrite(p, self.frame.copy())\n",
    "        print(\"[INFO] saved {}\".format(filename))\n",
    "\n",
    "#     def onClose(self):\n",
    "#         # set the stop event, cleanup the camera, and allow the rest of\n",
    "#         # the quit process to continue\n",
    "#         print(\"[INFO] closing...\")\n",
    "#         self.stopEvent.set()\n",
    "#         self.vs.stop()\n",
    "#         self.root.quit()\n",
    "        \n",
    "from __future__ import print_function\n",
    "# from pyimagesearch.photoboothapp import PhotoBoothApp\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# initialize the video stream and allow the camera sensor to warmup\n",
    "print(\"[INFO] warming up camera...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "# start the app\n",
    "pba = PhotoBoothApp(vs)\n",
    "pba.root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "import tkinter as tki\n",
    "import threading\n",
    "import datetime\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class PhotoBoothApp:\n",
    "    def __init__(self, vs, outputPath=r\"C:\\Users\\dell5567\\Desktop\\projectF\\outputs\"):\n",
    "        # store the video stream object and output path, then initialize\n",
    "        # the most recently read frame, thread for reading frames, and\n",
    "        # the thread stop event\n",
    "        self.vs = vs\n",
    "        self.outputPath = outputPath\n",
    "        self.frame = None\n",
    "        self.thread = None\n",
    "        self.stopEvent = None\n",
    "        # initialize the root window and image panel\n",
    "        self.root = tki.Tk()\n",
    "        \n",
    "        ## Grid sizing behavior in window\n",
    "        self.root.grid_rowconfigure(0, weight=1)\n",
    "        self.root.grid_columnconfigure(0, weight=1)\n",
    "        self.cnv = tki.Canvas(self.root)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.panel = None\n",
    "\n",
    "        # create a button, that when pressed, will take the current\n",
    "        # frame and save it to file\n",
    "        btn = tki.Button(self.root, text=\"Snapshot!\",\n",
    "            command=self.takeSnapshot)\n",
    "        btn.grid(row=1, column=0)\n",
    " \n",
    "\n",
    "\n",
    "         \n",
    "        \n",
    "        ## Frame in canvas\n",
    "        self.frm = tki.Frame(self.cnv).grid(row=0, column=1)\n",
    "        vScroll = tki.Scrollbar(self.frm, orient=\"vertical\")\n",
    "        vScroll.grid(row=0,column=2)        \n",
    "        \n",
    "        ## This puts the frame in the canvas's scrollable zone\n",
    "        self.cnv.create_window(0, 0, window=self.frm)\n",
    "        ## Frame contents\n",
    "        image = Image.open(r\"C:\\Users\\dell5567\\Desktop\\arc1.png\")\n",
    "        \n",
    "        \n",
    "        tkimage = ImageTk.PhotoImage(image)\n",
    "        myvar=tki.Label(self.frm,image = tkimage)\n",
    "        myvar.image = tkimage\n",
    "        myvar.grid()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         photo = ImageTk.PhotoImage(image)\n",
    "#         label = tki.Label(image=photo)\n",
    "#         label.image = photo # keep a reference!\n",
    "#         label.grid(row=0, column=1)\n",
    "\n",
    "#         label.image = photo\n",
    "#         label.grid(row=1, column=1)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#         !!!!!!!!!!\n",
    "        \n",
    "#         !!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # start a thread that constantly pools the video sensor for\n",
    "        # the most recently read frame\n",
    "        self.stopEvent = threading.Event()\n",
    "        self.thread = threading.Thread(target=self.videoLoop, args=())\n",
    "        self.thread.start()\n",
    "        # set a callback to handle when the window is closed\n",
    "#         self.root.wm_title(\"PyImageSearch PhotoBooth\")\n",
    "#         self.root.wm_protocol(\"WM_DELETE_WINDOW\", self.onClose)\n",
    "\n",
    "    def videoLoop(self):\n",
    "        # DISCLAIMER:\n",
    "        # I'm not a GUI developer, nor do I even pretend to be. This\n",
    "        # try/except statement is a pretty ugly hack to get around\n",
    "        # a RunTime error that Tkinter throws due to threading\n",
    "        try:\n",
    "            # keep looping over frames until we are instructed to stop\n",
    "            while not self.stopEvent.is_set():\n",
    "                # grab the frame from the video stream and resize it to\n",
    "                # have a maximum width of 300 pixels\n",
    "                self.frame = self.vs.read()\n",
    "                self.frame = imutils.resize(self.frame, width=400)\n",
    "\n",
    "                # OpenCV represents images in BGR order; however PIL\n",
    "                # represents images in RGB order, so we need to swap\n",
    "                # the channels, then convert to PIL and ImageTk format\n",
    "                image = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB)\n",
    "                image = Image.fromarray(image)\n",
    "                image = ImageTk.PhotoImage(image)\n",
    "\n",
    "                # if the panel is not None, we need to initialize it\n",
    "                if self.panel is None:\n",
    "                    self.panel = tki.Label(image=image)\n",
    "                    self.panel.image = image\n",
    "                    self.panel.grid(row=0, column=0)\n",
    "\n",
    "                # otherwise, simply update the panel\n",
    "                else:\n",
    "                    self.panel.configure(image=image)\n",
    "                    self.panel.image = image\n",
    "        except RuntimeError:            \n",
    "            print(\"[INFO] caught a RuntimeError\")\n",
    "\n",
    "    def takeSnapshot(self):\n",
    "        # grab the current timestamp and use it to construct the\n",
    "        # output path\n",
    "        ts = datetime.datetime.now()\n",
    "        filename = \"{}.jpg\".format(ts.strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "        p = os.path.sep.join((self.outputPath, filename))\n",
    "        # save the file\n",
    "        cv2.imwrite(p, self.frame.copy())\n",
    "        print(\"[INFO] saved {}\".format(filename))\n",
    "\n",
    "#     def onClose(self):\n",
    "#         # set the stop event, cleanup the camera, and allow the rest of\n",
    "#         # the quit process to continue\n",
    "#         print(\"[INFO] closing...\")\n",
    "#         self.stopEvent.set()\n",
    "#         self.vs.stop()\n",
    "#         self.root.quit()\n",
    "        \n",
    "from __future__ import print_function\n",
    "# from pyimagesearch.photoboothapp import PhotoBoothApp\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "# initialize the video stream and allow the camera sensor to warmup\n",
    "print(\"[INFO] warming up camera...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(2.0)\n",
    "# start the app\n",
    "pba = PhotoBoothApp(vs)\n",
    "pba.root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import tkinter and all its functions\n",
    "from tkinter import * \n",
    "\n",
    "root = Tk() # create root window\n",
    "root.title(\"GUI Layout\") # title of the GUI window\n",
    "root.maxsize(1000, 600) # specify the max size the window can expand to\n",
    "root.config(bg=\"skyblue\") # specify background color\n",
    "root.geometry(\"1000x600\")\n",
    "\n",
    "# root.columnconfigure(0, weight=0)\n",
    "# root.rowconfigure(0, weight=0)   \n",
    "\n",
    "\n",
    "# Create left and right frames\n",
    "left_frame = Frame(root, width=750, height=600, bg='grey')\n",
    "left_frame.place(x=0, y=0)\n",
    "\n",
    "\n",
    "# left_frame.columnconfigure(0, weight=0)\n",
    "# left_frame.rowconfigure(0, weight=0)\n",
    "        \n",
    "        \n",
    "        \n",
    "right_frame = Frame(root, width=250, height=600, bg='red')\n",
    "right_frame.place(x=750, y=0)\n",
    "\n",
    "# Create frames and labels in left_frame\n",
    "# Label(left_frame, text=\"Original Image\").grid(row=0, column=0, padx=1, pady=1)\n",
    "\n",
    "# load image to be \"edited\"\n",
    "image = PhotoImage(r\"C:\\Users\\dell5567\\Desktop\\arc1.png\")\n",
    "original_image = image.subsample(3,3) # resize image using subsample\n",
    "\n",
    "# Display image in left_frame\n",
    "Label(left_frame, image=image,justify=\"center\").place(x=100,y=0)\n",
    "\n",
    "# Display image in right_frame\n",
    "# Label(right_frame, image=original_image).grid(row=0, column=0, padx=1, pady=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "listbox = Listbox(right_frame,width=30,height=35)\n",
    "# listbox.place(x=2,y=2)\n",
    "listbox.pack(side=\"left\",fill=\"y\")\n",
    "\n",
    "\n",
    "scrollbar = Scrollbar(right_frame,orient=\"vertical\")\n",
    "scrollbar.pack(fill=\"y\")\n",
    "\n",
    "for i in range(100):\n",
    "    listbox.insert(END, i)\n",
    "\n",
    "# attach listbox to scrollbar\n",
    "listbox.config(yscrollcommand=scrollbar.set)\n",
    "scrollbar.config(command=listbox.yview)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tkinter and all its functions\n",
    "from tkinter import * \n",
    "\n",
    "root = Tk() # create root window\n",
    "root.title(\"Basic GUI Layout\") # title of the GUI window\n",
    "root.maxsize(900, 600) # specify the max size the window can expand to\n",
    "root.config(bg=\"skyblue\") # specify background color\n",
    "\n",
    "# Create left and right frames\n",
    "left_frame = Frame(root, width=200, height=400, bg='grey')\n",
    "left_frame.grid(row=0, column=0, padx=10, pady=5)\n",
    "right_frame = Frame(root, width=650, height=400, bg='grey')\n",
    "right_frame.grid(row=0, column=1, padx=10, pady=5)\n",
    "\n",
    "# Create frames and labels in left_frame\n",
    "Label(left_frame, text=\"Original Image\").grid(row=0, column=0, padx=5, pady=5)\n",
    "\n",
    "# load image to be \"edited\"\n",
    "image = PhotoImage(file=\"rain.gif\")\n",
    "original_image = image.subsample(3,3) # resize image using subsample\n",
    "Label(left_frame, image=original_image).grid(row=1, column=0, padx=5, pady=5)\n",
    "\n",
    "# Display image in right_frame\n",
    "Label(right_frame, image=image).grid(row=0,column=0, padx=5, pady=5)\n",
    "\n",
    "# Create tool bar frame\n",
    "tool_bar = Frame(left_frame, width=180, height=185)\n",
    "tool_bar.grid(row=2, column=0, padx=5, pady=5)\n",
    "\n",
    "# Example labels that serve as placeholders for other widgets \n",
    "Label(tool_bar, text=\"Tools\", relief=RAISED).grid(row=0, column=0, padx=5, pady=3, ipadx=10) # ipadx is padding inside the Label widget\n",
    "Label(tool_bar, text=\"Filters\", relief=RAISED).grid(row=0, column=1, padx=5, pady=3, ipadx=10)\n",
    "\n",
    "# Example labels that could be displayed under the \"Tool\" menu\n",
    "Label(tool_bar, text=\"Select\").grid(row=1, column=0, padx=5, pady=5)\n",
    "Label(tool_bar, text=\"Crop\").grid(row=2, column=0, padx=5, pady=5)\n",
    "Label(tool_bar, text=\"Rotate & Flip\").grid(row=3, column=0, padx=5, pady=5)\n",
    "Label(tool_bar, text=\"Resize\").grid(row=4, column=0, padx=5, pady=5)\n",
    "Label(tool_bar, text=\"Exposure\").grid(row=5, column=0, padx=5, pady=5)\n",
    "\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
